{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the manual data parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The first step is to import the packages necessary to format and clean the data\n",
    "#### If you're having trouble running the script, ensure you have the pandas packed installed by opening \"windows powershell\", and type, \"pip install pandas\" and hit enter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At the this time, the Enspire raw file and OD file need the file path manually copied and pasted - no formatting is necessary - just select copy path in folder location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "enspire_path = r\"L:\\Assay Development\\amber brown\\SSF HPB runs\\SSF00599\\SSF00599_enspire.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_path = r\"L:\\Molecular Sciences\\Small Scale Runs\\SSF00599 HTP v2 (QC) Assess 96DW plate alternatives_MS\\Assays\\OD\\Processed\\SSF00599 HTP OD600_copy.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These are the well ids that will link the Enspire values back to the source value, as well as link the Enspire data to the OD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_ids = ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A10',\n",
    "             'B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B09', 'B10',\n",
    "             'C01', 'C02', 'C03', 'C04', 'C05', 'C06', 'C07', 'C08', 'C09', 'C10', \n",
    "             'D01', 'D02', 'D03', 'D04', 'D05', 'D06', 'D07', 'D08', 'D09', 'D10',\n",
    "             'E01', 'E02', 'E03', 'E04', 'E05', 'E06', 'E07', 'E08', 'E09', 'E10',\n",
    "             'F01', 'F02', 'F03', 'F04', 'F05', 'F06', 'F07', 'F08', 'F09', 'F10',\n",
    "             'G01', 'G02', 'G03', 'G04', 'G05', 'G06', 'G07', 'G08', 'G09', 'G10',\n",
    "             'H01', 'H02', 'H03', 'H04', 'H05', 'H06', 'H07', 'H08', 'H09', 'H10',\n",
    "             ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is a function that will be called later in the script. Once the data is cleaned and formatted, this function will make calculations\n",
    "##### Note that the \"dilution_volumes = \" list values will need to be replace with experimental values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculations(clean_df, standard=0):\n",
    "    \n",
    "    ### Replace the values within the brackets to the experimental volumes used! \n",
    "    ### Enter as integer or float separated by comma within the square brackets\n",
    "    dilution_volumes = [1, 0.166666667, 0.027777778, 0.00462963, 0.000771605, 0.000128601]\n",
    "    \n",
    "    if standard == 1:\n",
    "        clean_df[[\"STD_1\", \"STD_2\", \"STD_3\", \"STD_4\", \"STD_5\", \"STD_6\"]] = clean_df[\n",
    "            [\"STD_1\", \"STD_2\", \"STD_3\", \"STD_4\", \"STD_5\", \"STD_6\"]].astype(float)\n",
    "        for n in range(1, 6):\n",
    "            clean_df[f\"std_slope_{n}\"] = round((clean_df[f\"STD_{n + 1}\"] - clean_df[f\"STD_{n}\"]) /\n",
    "                                              (dilution_volumes[n] - dilution_volumes[n -1]), 2)\n",
    "\n",
    "        clean_df[\"max_std_slope\"] = clean_df[\n",
    "            [\"std_slope_1\", \"std_slope_2\", \"std_slope_3\", \"std_slope_4\", \"std_slope_5\"]\n",
    "        ].max(axis=1)\n",
    "        \n",
    "        return clean_df\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        clean_df[[\"Alpha_1\", \"Alpha_2\", \"Alpha_3\", \"Alpha_4\", \"Alpha_5\", \"Alpha_6\"]] = clean_df[\n",
    "            [\"Alpha_1\", \"Alpha_2\", \"Alpha_3\", \"Alpha_4\", \"Alpha_5\", \"Alpha_6\"]\n",
    "        ].astype(float)\n",
    "        \n",
    "        clean_df[[\"DNA_1\", \"DNA_2\", \"DNA_3\", \"DNA_4\", \"DNA_5\", \"DNA_6\"]] = clean_df[\n",
    "            [\"DNA_1\", \"DNA_2\", \"DNA_3\", \"DNA_4\", \"DNA_5\", \"DNA_6\"]\n",
    "        ].astype(float)\n",
    "\n",
    "        for n in range(1, 6):\n",
    "            clean_df[f\"alpha_slope_{n}\"] = round((clean_df[f\"Alpha_{n + 1}\"] - (clean_df[f\"Alpha_{n}\"])) /\n",
    "                                                 (dilution_volumes[n] - dilution_volumes[n - 1]), 2)\n",
    "        clean_df[\"max_alpha_slope\"] = clean_df[\n",
    "            [\"alpha_slope_1\", \"alpha_slope_2\", \"alpha_slope_3\", \"alpha_slope_4\", \"alpha_slope_5\"]\n",
    "        ].max(axis=1)\n",
    "\n",
    "        for n in range(1, 6):\n",
    "            clean_df[f\"dna_slope_{n}\"] = round((clean_df[f\"DNA_{n + 1}\"] - clean_df[f\"DNA_{n}\"]) /\n",
    "                                                    (dilution_volumes[n] - dilution_volumes[n - 1]), 2)\n",
    "        clean_df[\"max_dna_slope\"] = clean_df[\n",
    "            [\"dna_slope_1\", \"dna_slope_2\", \"dna_slope_3\", \"dna_slope_4\", \"dna_slope_5\"]\n",
    "        ].max(axis=1)\n",
    "\n",
    "        clean_df[\"max_alpha_slope/max_dna_slope\"] = round(clean_df[\"max_alpha_slope\"] / clean_df[\"max_dna_slope\"], 2)\n",
    "\n",
    "        return clean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This section of code will import the OD file, format the column headings, remove empty data, and drop unnecessary columns, and create a unique ID that will help link the data to the Enspire data from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_data = pd.read_excel(od_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in od_data.columns:\n",
    "    od_data.rename(columns={column: column.title()}, inplace=True)\n",
    "od_data.dropna(subset=[\"Ssf Exp\"], inplace=True)\n",
    "od_data[\"Od600\"] = od_data[\"Od600\"].replace(\" \", \"0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [\"Ssf Exp\", \"Seed Plate\", \"Seed Well\", \"Harvest Plate\", \"Harvest Well\"]\n",
    "od_data_clean = od_data.drop(columns=drop_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'od_data_clean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-aa7d2b7c41df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mod_data_clean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'od_data_clean' is not defined"
     ]
    }
   ],
   "source": [
    "od_data_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_data_clean.insert(0, \"Id\", od_data_clean[\"Harvest Sample Id\"].apply(lambda x: str(x).split(\"-\", 1)[-1]))\n",
    "od_data_clean.insert(1, \"Plate\", od_data_clean[\"Id\"].apply(lambda x:str(x).split(\"-\")[0]))\n",
    "od_data_clean.insert(2, \"Well_Id\", od_data_clean[\"Id\"].apply(lambda x:str(x).split(\"-\")[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This code will show a snapshot of the newly formatted datafframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Plate</th>\n",
       "      <th>Well_Id</th>\n",
       "      <th>Row</th>\n",
       "      <th>Column</th>\n",
       "      <th>Seed Sample Id</th>\n",
       "      <th>Harvest Sample Id</th>\n",
       "      <th>Sample Type</th>\n",
       "      <th>Strain</th>\n",
       "      <th>Bio-Replicate  No.</th>\n",
       "      <th>Induction Temp</th>\n",
       "      <th>Proprionate (Mm)</th>\n",
       "      <th>Arabinose (Um)</th>\n",
       "      <th>Od600</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P1-A01</td>\n",
       "      <td>P1</td>\n",
       "      <td>A01</td>\n",
       "      <td>A</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SSF00599-P1-A03</td>\n",
       "      <td>SSF00599-P1-A01</td>\n",
       "      <td>negative control</td>\n",
       "      <td>ABS08019</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21 C</td>\n",
       "      <td>20.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>15.078720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P1-A02</td>\n",
       "      <td>P1</td>\n",
       "      <td>A02</td>\n",
       "      <td>A</td>\n",
       "      <td>9.0</td>\n",
       "      <td>SSF00599-P1-A09</td>\n",
       "      <td>SSF00599-P1-A02</td>\n",
       "      <td>positive control</td>\n",
       "      <td>ABS11963</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21 C</td>\n",
       "      <td>20.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>3.093408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P1-A03</td>\n",
       "      <td>P1</td>\n",
       "      <td>A03</td>\n",
       "      <td>A</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SSF00599-P2-A03</td>\n",
       "      <td>SSF00599-P1-A03</td>\n",
       "      <td>negative control</td>\n",
       "      <td>ABS08019</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21 C</td>\n",
       "      <td>20.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>16.090825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P1-A04</td>\n",
       "      <td>P1</td>\n",
       "      <td>A04</td>\n",
       "      <td>A</td>\n",
       "      <td>9.0</td>\n",
       "      <td>SSF00599-P2-A09</td>\n",
       "      <td>SSF00599-P1-A04</td>\n",
       "      <td>positive control</td>\n",
       "      <td>ABS11963</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21 C</td>\n",
       "      <td>20.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>2.692000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P1-A05</td>\n",
       "      <td>P1</td>\n",
       "      <td>A05</td>\n",
       "      <td>A</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SSF00599-P3-A03</td>\n",
       "      <td>SSF00599-P1-A05</td>\n",
       "      <td>negative control</td>\n",
       "      <td>ABS08019</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21 C</td>\n",
       "      <td>20.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>10.496483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id Plate Well_Id Row  Column   Seed Sample Id Harvest Sample Id  \\\n",
       "0  P1-A01    P1     A01   A     3.0  SSF00599-P1-A03   SSF00599-P1-A01   \n",
       "1  P1-A02    P1     A02   A     9.0  SSF00599-P1-A09   SSF00599-P1-A02   \n",
       "2  P1-A03    P1     A03   A     3.0  SSF00599-P2-A03   SSF00599-P1-A03   \n",
       "3  P1-A04    P1     A04   A     9.0  SSF00599-P2-A09   SSF00599-P1-A04   \n",
       "4  P1-A05    P1     A05   A     3.0  SSF00599-P3-A03   SSF00599-P1-A05   \n",
       "\n",
       "        Sample Type    Strain  Bio-Replicate  No. Induction Temp  \\\n",
       "0  negative control  ABS08019                 1.0           21 C   \n",
       "1  positive control  ABS11963                 1.0           21 C   \n",
       "2  negative control  ABS08019                 1.0           21 C   \n",
       "3  positive control  ABS11963                 1.0           21 C   \n",
       "4  negative control  ABS08019                 1.0           21 C   \n",
       "\n",
       "   Proprionate (Mm)  Arabinose (Um)      Od600  \n",
       "0              20.0           250.0  15.078720  \n",
       "1              20.0           250.0   3.093408  \n",
       "2              20.0           250.0  16.090825  \n",
       "3              20.0           250.0   2.692000  \n",
       "4              20.0           250.0  10.496483  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "od_data_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The next bloc of code will import the Enspire data, creating a dataframe for the alpha signals and dna signals respectively. \n",
    "##### Note that this data will require manual input of plate ids and source plates at the \" source_plates = [] \" and \" plates  = [] \" variables - please enter in the following format: [\"P1\", \"P2\", \"P3\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "source_plates = [\"P1\"]\n",
    "plates = [\"P1\", \"P2\", \"P3\", \"P4\"]\n",
    "all_alpha_df = pd.DataFrame()\n",
    "all_dna_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for plate in plates:\n",
    "    alpha_df = pd.read_csv(\n",
    "        enspire_path,\n",
    "        header=None,\n",
    "        names=np.arange(0,25),\n",
    "        usecols=np.arange(0, 25), \n",
    "        skiprows=7 + count * 48, \n",
    "        nrows=16\n",
    "    )\n",
    "    alpha_df.insert(1, \"ID\", f\"{plate}\" + \"-\" + alpha_df[0])\n",
    "    alpha_df.drop(0, axis=1, inplace=True)\n",
    "    all_alpha_df = pd.concat([all_alpha_df, alpha_df])\n",
    "    \n",
    "    dna_df = pd.read_csv(\n",
    "        enspire_path,\n",
    "        header=None,\n",
    "        names=np.arange(24, 49),\n",
    "        usecols=np.arange(0, 25),\n",
    "        skiprows=31 + count * 48,\n",
    "        nrows=16\n",
    "    )\n",
    "    dna_df.insert(1, \"ID\", f\"{plate}\" + \"-\" + dna_df[24])\n",
    "    dna_df.drop(24, axis=1, inplace=True)\n",
    "    all_dna_df = pd.concat([all_dna_df, dna_df])\n",
    "\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This next bloc of code will prepare empty dataframes where data from the enspire file will be captured and concatenated. \n",
    "##### Note that the \"std_conc = \" list values will need to be replaced with concentrations used in experiment! Please enter values as integer or float separated by a comma, inside of square brackets '[ ]' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_sig_cols = [\"ProxiPlate\"] + [f\"Alpha_{n}\" for n in range(1, 7)]\n",
    "all_alpha_concat_df = pd.DataFrame(columns=alpha_sig_cols)\n",
    "all_rep_concat_df = pd.DataFrame(columns=alpha_sig_cols)\n",
    "\n",
    "dna_sig_cols = [\"ProxiPlate\"] + [f\"DNA_{n}\" for n in range(1, 7)]\n",
    "all_dna_concat_df = pd.DataFrame(columns=dna_sig_cols)\n",
    "all_dna_rep_concat_df = pd.DataFrame(columns=dna_sig_cols)\n",
    "\n",
    "std_sig_cols = [\"ProxiPlate\"] + [\"Concentration (nm)\"] + [f\"STD_{n}\" for n in range(1, 7)]\n",
    "all_std_concat_df = pd.DataFrame(columns=std_sig_cols)\n",
    "\n",
    "std_section = \"A B C D\".split()\n",
    "\n",
    "# Replace values with experimental values!\n",
    "std_conc = [50, 16.7, 5.6, 1.9]\n",
    "\n",
    "# Row and column counters the will help capture the data we need for our end dataframe\n",
    "s_row = 0\n",
    "e_row = 10\n",
    "std_s_row = 12\n",
    "std_e_row = 16\n",
    "\n",
    "# This indicates the section of the plate the for loop will loop through\n",
    "sections = [1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This next bloc creates a nested for loop that will loop through each plate, and each section of the plate to capture the data we want, and concatenate data to specified dataframe, separating Alpha signals, DNA signals, and standards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for plate in plates:\n",
    "    s_col = 1\n",
    "    e_col = 7\n",
    "    for section in sections:\n",
    "        alpha_capture_df = all_alpha_df.iloc[s_row: e_row, s_col: e_col]\n",
    "        alpha_capture_df.insert(0, \"ProxiPlate\", plate)\n",
    "        alpha_capture_df.columns= alpha_sig_cols\n",
    "\n",
    "        dna_capture_df = all_dna_df.iloc[s_row: e_row, s_col: e_col]\n",
    "        dna_capture_df.insert(0, \"ProxiPlate\", plate)\n",
    "        dna_capture_df.columns= dna_sig_cols\n",
    "\n",
    "        std_capture_df = all_alpha_df.iloc[std_s_row:std_e_row, s_col: e_col]\n",
    "        std_capture_df.insert(0, \"ProxiPlate\", f\"{plate}-{std_section[section - 1]}\")\n",
    "        std_capture_df.insert(1, \"Concentration (nm)\", std_conc)\n",
    "        std_capture_df.columns= std_sig_cols\n",
    "\n",
    "        if section % 2 != 0:\n",
    "            all_alpha_concat_df = pd.concat([all_alpha_concat_df, alpha_capture_df])\n",
    "            all_dna_concat_df = pd.concat([all_dna_concat_df, dna_capture_df])\n",
    "            all_std_concat_df = pd.concat([all_std_concat_df, std_capture_df])\n",
    "\n",
    "        else:\n",
    "            all_rep_concat_df = pd.concat([all_rep_concat_df, alpha_capture_df])\n",
    "            all_dna_rep_concat_df = pd.concat([all_dna_rep_concat_df, dna_capture_df])\n",
    "            all_std_concat_df = pd.concat([all_std_concat_df, std_capture_df])\n",
    "\n",
    "        s_col += 6\n",
    "        e_col += 6\n",
    "        \n",
    "    s_row += 16\n",
    "    e_row += 16\n",
    "    std_s_row += 16\n",
    "    std_e_row += 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here the unique ID will be created, which will be used to merge Alpha and DNA signals to one dataframe, and eventuallly used to link to OD dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_alpha_concat_df.insert(1, \"Well_Id\", well_ids)\n",
    "all_alpha_concat_df.insert(2, \"HPB_Id\", all_alpha_concat_df[\"ProxiPlate\"] + \"-\" + all_alpha_concat_df[\"Well_Id\"])\n",
    "all_alpha_concat_df.insert(0, \"Id\", source_plates[0] + \"-\" + all_alpha_concat_df[\"Well_Id\"])\n",
    "\n",
    "all_rep_concat_df.insert(1, \"Well_Id\", well_ids)\n",
    "all_rep_concat_df.insert(2, \"HPB_Id\", all_rep_concat_df[\"ProxiPlate\"] + \"-\" + all_rep_concat_df[\"Well_Id\"])\n",
    "all_rep_concat_df.insert(0, \"Id\", source_plates[0] + \"-\" + all_rep_concat_df[\"Well_Id\"])\n",
    "\n",
    "all_dna_concat_df.insert(1, \"Well_Id\", well_ids)\n",
    "all_dna_concat_df.insert(2, \"HPB_Id\", all_dna_concat_df[\"ProxiPlate\"] + \"-\" + all_dna_concat_df[\"Well_Id\"])\n",
    "all_dna_concat_df.insert(0, \"Id\", source_plates[0] + \"-\" + all_dna_concat_df[\"Well_Id\"])\n",
    "\n",
    "all_dna_rep_concat_df.insert(1, \"Well_Id\", well_ids)\n",
    "all_dna_rep_concat_df.insert(2, \"HPB_Id\", all_dna_rep_concat_df[\"ProxiPlate\"] + \"-\" + all_dna_rep_concat_df[\"Well_Id\"])\n",
    "all_dna_rep_concat_df.insert(0, \"Id\", source_plates[0] + \"-\" + all_dna_rep_concat_df[\"Well_Id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These two lines will merge Alpha and DNA signals for the main and replicate data respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.merge(all_alpha_concat_df, all_dna_concat_df, on=[\"Id\", \"ProxiPlate\", \"Well_Id\", \"HPB_Id\"])\n",
    "rep_df = pd.merge(all_rep_concat_df, all_dna_rep_concat_df, on=[\"Id\", \"ProxiPlate\", \"Well_Id\",\"HPB_Id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is where the aforementioned function, \"def calculations\" is called. This will take each of the created data frames, and make the necessary slope calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProxiPlate</th>\n",
       "      <th>Concentration (nm)</th>\n",
       "      <th>STD_1</th>\n",
       "      <th>STD_2</th>\n",
       "      <th>STD_3</th>\n",
       "      <th>STD_4</th>\n",
       "      <th>STD_5</th>\n",
       "      <th>STD_6</th>\n",
       "      <th>std_slope_1</th>\n",
       "      <th>std_slope_2</th>\n",
       "      <th>std_slope_3</th>\n",
       "      <th>std_slope_4</th>\n",
       "      <th>std_slope_5</th>\n",
       "      <th>max_std_slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>P1-A</td>\n",
       "      <td>50.0</td>\n",
       "      <td>62584.0</td>\n",
       "      <td>52195.0</td>\n",
       "      <td>2773.0</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>762.0</td>\n",
       "      <td>971.0</td>\n",
       "      <td>12466.8</td>\n",
       "      <td>355838.4</td>\n",
       "      <td>76118.4</td>\n",
       "      <td>64540.79</td>\n",
       "      <td>-325036.86</td>\n",
       "      <td>355838.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>P1-A</td>\n",
       "      <td>16.7</td>\n",
       "      <td>62820.0</td>\n",
       "      <td>6389.0</td>\n",
       "      <td>951.0</td>\n",
       "      <td>868.0</td>\n",
       "      <td>957.0</td>\n",
       "      <td>1397.0</td>\n",
       "      <td>67717.2</td>\n",
       "      <td>39153.6</td>\n",
       "      <td>3585.6</td>\n",
       "      <td>-23068.80</td>\n",
       "      <td>-684288.12</td>\n",
       "      <td>67717.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>P1-A</td>\n",
       "      <td>5.6</td>\n",
       "      <td>25683.0</td>\n",
       "      <td>1249.0</td>\n",
       "      <td>990.0</td>\n",
       "      <td>917.0</td>\n",
       "      <td>903.0</td>\n",
       "      <td>2923.0</td>\n",
       "      <td>29320.8</td>\n",
       "      <td>1864.8</td>\n",
       "      <td>3153.6</td>\n",
       "      <td>3628.80</td>\n",
       "      <td>-3141504.56</td>\n",
       "      <td>29320.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>P1-A</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2818.0</td>\n",
       "      <td>1310.0</td>\n",
       "      <td>866.0</td>\n",
       "      <td>1151.0</td>\n",
       "      <td>969.0</td>\n",
       "      <td>2030.0</td>\n",
       "      <td>1809.6</td>\n",
       "      <td>3196.8</td>\n",
       "      <td>-12312.0</td>\n",
       "      <td>47174.40</td>\n",
       "      <td>-1650067.50</td>\n",
       "      <td>47174.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>P1-B</td>\n",
       "      <td>50.0</td>\n",
       "      <td>54960.0</td>\n",
       "      <td>43822.0</td>\n",
       "      <td>3587.0</td>\n",
       "      <td>2322.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>2244.0</td>\n",
       "      <td>13365.6</td>\n",
       "      <td>289692.0</td>\n",
       "      <td>54648.0</td>\n",
       "      <td>-20217.60</td>\n",
       "      <td>242611.24</td>\n",
       "      <td>289692.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>P4-C</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3392.0</td>\n",
       "      <td>1362.0</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>1152.0</td>\n",
       "      <td>1192.0</td>\n",
       "      <td>2436.0</td>\n",
       "      <td>1274.4</td>\n",
       "      <td>2030.4</td>\n",
       "      <td>-3628.80</td>\n",
       "      <td>-62208.01</td>\n",
       "      <td>2436.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>P4-D</td>\n",
       "      <td>50.0</td>\n",
       "      <td>84112.0</td>\n",
       "      <td>61885.0</td>\n",
       "      <td>4195.0</td>\n",
       "      <td>1382.0</td>\n",
       "      <td>1516.0</td>\n",
       "      <td>1408.0</td>\n",
       "      <td>26672.4</td>\n",
       "      <td>415368.0</td>\n",
       "      <td>121521.6</td>\n",
       "      <td>-34732.80</td>\n",
       "      <td>167961.63</td>\n",
       "      <td>415368.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>P4-D</td>\n",
       "      <td>16.7</td>\n",
       "      <td>95279.0</td>\n",
       "      <td>9288.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>1182.0</td>\n",
       "      <td>1172.0</td>\n",
       "      <td>1224.0</td>\n",
       "      <td>103189.2</td>\n",
       "      <td>56505.6</td>\n",
       "      <td>11145.6</td>\n",
       "      <td>2592.00</td>\n",
       "      <td>-80870.41</td>\n",
       "      <td>103189.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>P4-D</td>\n",
       "      <td>5.6</td>\n",
       "      <td>32766.0</td>\n",
       "      <td>1916.0</td>\n",
       "      <td>1271.0</td>\n",
       "      <td>1190.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>1311.0</td>\n",
       "      <td>37020.0</td>\n",
       "      <td>4644.0</td>\n",
       "      <td>3499.2</td>\n",
       "      <td>-21772.80</td>\n",
       "      <td>-57542.41</td>\n",
       "      <td>37020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>P4-D</td>\n",
       "      <td>1.9</td>\n",
       "      <td>5027.0</td>\n",
       "      <td>1497.0</td>\n",
       "      <td>1446.0</td>\n",
       "      <td>1496.0</td>\n",
       "      <td>1626.0</td>\n",
       "      <td>1743.0</td>\n",
       "      <td>4236.0</td>\n",
       "      <td>367.2</td>\n",
       "      <td>-2160.0</td>\n",
       "      <td>-33696.00</td>\n",
       "      <td>-181958.43</td>\n",
       "      <td>4236.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ProxiPlate  Concentration (nm)    STD_1    STD_2   STD_3   STD_4   STD_5  \\\n",
       "12       P1-A                50.0  62584.0  52195.0  2773.0  1011.0   762.0   \n",
       "13       P1-A                16.7  62820.0   6389.0   951.0   868.0   957.0   \n",
       "14       P1-A                 5.6  25683.0   1249.0   990.0   917.0   903.0   \n",
       "15       P1-A                 1.9   2818.0   1310.0   866.0  1151.0   969.0   \n",
       "12       P1-B                50.0  54960.0  43822.0  3587.0  2322.0  2400.0   \n",
       "..        ...                 ...      ...      ...     ...     ...     ...   \n",
       "15       P4-C                 1.9   3392.0   1362.0  1185.0  1138.0  1152.0   \n",
       "12       P4-D                50.0  84112.0  61885.0  4195.0  1382.0  1516.0   \n",
       "13       P4-D                16.7  95279.0   9288.0  1440.0  1182.0  1172.0   \n",
       "14       P4-D                 5.6  32766.0   1916.0  1271.0  1190.0  1274.0   \n",
       "15       P4-D                 1.9   5027.0   1497.0  1446.0  1496.0  1626.0   \n",
       "\n",
       "     STD_6  std_slope_1  std_slope_2  std_slope_3  std_slope_4  std_slope_5  \\\n",
       "12   971.0      12466.8     355838.4      76118.4     64540.79   -325036.86   \n",
       "13  1397.0      67717.2      39153.6       3585.6    -23068.80   -684288.12   \n",
       "14  2923.0      29320.8       1864.8       3153.6      3628.80  -3141504.56   \n",
       "15  2030.0       1809.6       3196.8     -12312.0     47174.40  -1650067.50   \n",
       "12  2244.0      13365.6     289692.0      54648.0    -20217.60    242611.24   \n",
       "..     ...          ...          ...          ...          ...          ...   \n",
       "15  1192.0       2436.0       1274.4       2030.4     -3628.80    -62208.01   \n",
       "12  1408.0      26672.4     415368.0     121521.6    -34732.80    167961.63   \n",
       "13  1224.0     103189.2      56505.6      11145.6      2592.00    -80870.41   \n",
       "14  1311.0      37020.0       4644.0       3499.2    -21772.80    -57542.41   \n",
       "15  1743.0       4236.0        367.2      -2160.0    -33696.00   -181958.43   \n",
       "\n",
       "    max_std_slope  \n",
       "12       355838.4  \n",
       "13        67717.2  \n",
       "14        29320.8  \n",
       "15        47174.4  \n",
       "12       289692.0  \n",
       "..            ...  \n",
       "15         2436.0  \n",
       "12       415368.0  \n",
       "13       103189.2  \n",
       "14        37020.0  \n",
       "15         4236.0  \n",
       "\n",
       "[64 rows x 14 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculations(main_df)\n",
    "calculations(rep_df)\n",
    "calculations(all_std_concat_df, standard=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 29)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, the main and replicate dataframe will be merged with the OD dataframe based on the unique ID provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_and_od = pd.merge(od_data_clean, main_df, on=[\"Id\", \"Well_Id\"])\n",
    "rep_and_od = pd.merge(od_data_clean, rep_df, on=[\"Id\", \"Well_Id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last, our data will be exported to an excel spreadsheet, with the main data, replicate data, and standard data going each to a separate sheet within the workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(\"Manual_Data.xlsx\") as writer:\n",
    "    main_and_od.to_excel(writer, sheet_name=\"Source_Signals\")\n",
    "    rep_and_od.to_excel(writer, sheet_name=\"Rep_Signals\")\n",
    "    all_std_concat_df.to_excel(writer, sheet_name=\"Standards\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
